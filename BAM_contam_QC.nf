#!/usr/bin/env nextflow
/* Pipeline for QC steps starting from BAMs rather than final VCFs.      *
 * QC steps:                                                             *
 *  VerifyBamID2                                                         *
 *  mutserve -> haplocheck                                               *
 *  somalier extract -> somalier relate                                  */

//Default paths, globs, and regexes:
params.bam_glob = "${projectDir}/BAMs/*.ba{m,m.bai}"
//The first capture group in the following regex must be a unique identifier
// for the library and sequencing run:
params.id_regex = ~/^(\p{Alnum}+)_MD_IR_recal/
//I'm setting up file names such that they follow this scheme:
//[sample ID]_MD_IR_recal*.bam
//^^^^^^^^^^^
//Capture this part

//Reference-related parameters for the pipeline:
params.ref_prefix = "/gpfs/gibbs/pi/tucci/pfr8/refs"
params.ref = "${params.ref_prefix}/1kGP/hs37d5/hs37d5.fa"

//params.vbid2_path = "/home/pfr8/project/conda_envs/VerifyBamID2env/share/verifybamid2-2.0.1-6"

//VerifyBamID2 panel SVD files:
params.panel_id = "hgdp.100k.b37"
params.vbid2_prefix = "/home/pfr8/project/conda_envs/VerifyBamID2env/share/verifybamid2-2.0.1-6/resource"
params.vbid2_panel = "${params.vbid2_prefix}/${params.panel_id}.vcf.gz.dat"

//Set up the channel of BAMs
Channel
   .fromFilePairs(params.bam_glob, checkIfExists: true) { file -> (file.getSimpleName() =~ params.id_regex)[0][1] }
   .ifEmpty { error "Unable to find BAMs matching glob: ${params.bam_glob}" }
   .tap { bams_VBID, bams_mutserve, bams_somalier }
   .subscribe { println "Added ${it[0]} to bams_* channels" }

//Set up the file channels for the ref and its various index components:
//Inspired by the IARC alignment-nf pipeline
//fai is generated by samtools faidx, and dict is generated by Picard and used by GATK
ref = file(params.ref, checkIfExists: true)
ref_dict = file(params.ref.replaceFirst("[.]fn?a(sta)?([.]gz)?", ".dict"), checkIfExists: true)
ref_fai = file(params.ref+'.fai', checkIfExists: true)

//Set up the file channels for the panel SVD components:
panel_UD = file(params.vbid2_panel+'.UD', checkIfExists: true)
panel_bed = file(params.vbid2_panel+'.bed', checkIfExists: true)
panel_mu = file(params.vbid2_panel+'.mu', checkIfExists: true)

//mutserve/haplogrep rCRS reference path:
params.rcrs = '/home/pfr8/bin/mutserve/2.0.0-rc12/rCRS.fasta'
rcrs = file(params.rcrs, checkIfExists: true)

//somalier sites to extract:
params.somalier_sites = '/home/pfr8/bin/somalier-0.2.15/sites.GRCh37.vcf.gz'
somalier_sites = file(params.somalier_sites, checkIfExists: true)

//Default parameter values:
//VerifyBamID2 parameters:
//Perform mapping quality adjustment during pileup:
//Default for VerifyBamID is 40, to turn off adjustment, set to 0
params.adjustMQ = 40

//Defaults for cpus, memory, and time for each process:
//VerifyBamID2
params.vbid2_cpus = 4
params.vbid2_mem = 1
params.vbid2_timeout = '1h'
//mutserve+haplocheck
params.haplocheck_cpus = 1
params.haplocheck_mem = 2
params.haplocheck_timeout = '1h'
//somalier extract
params.extract_cpus = 1
params.extract_mem = 1
params.extract_timeout = '2h'
//somalier relate
params.relate_cpus = 1
params.relate_mem = 2
params.relate_timeout = '1h'

process vbid2 {
   tag "${id}"

   cpus params.vbid2_cpus
   memory { params.vbid2_mem.plus(task.attempt.minus(1).multiply(1))+' GB' }
   time { task.attempt == 3 ? '12h' : params.vbid2_timeout }
   errorStrategy { task.exitStatus in ([1]+(134..140).collect()) ? 'retry' : 'terminate' }
   maxRetries 2

   publishDir path: "${params.output_dir}/logs", mode: 'copy', pattern: '*.std{err,out}'
   publishDir path: "${params.output_dir}/VBID2_outputs", mode: 'copy', pattern: '*.{selfSM,Ancestry}'

   input:
   tuple val(id), file(bambai) from bams_VBID
   file ref
   file ref_dict
   file ref_fai
   file panel_UD
   file panel_bed
   file panel_mu

   output:
   tuple path("${id}_${params.panel_id}_adjustMQ${params.adjustMQ}_VerifyBamID2.stderr"), path("${id}_${params.panel_id}_adjustMQ${params.adjustMQ}_VerifyBamID2.stdout") into vbid2_logs
   tuple path("${id}_${params.panel_id}_adjustMQ${params.adjustMQ}.selfSM"), path("${id}_${params.panel_id}_adjustMQ${params.adjustMQ}.Ancestry") into vbid2_outputs

   shell:
   '''
   module load !{params.mod_miniconda}
   conda activate VerifyBamID2env
   !{params.vbid2_path}/VerifyBamID --SVDPrefix !{params.panel_id}.vcf.gz.dat --Reference !{ref} --Output !{id}_!{params.panel_id}_adjustMQ!{params.adjustMQ} --BamFile !{bambai[0]} 2> !{id}_!{params.panel_id}_adjustMQ!{params.adjustMQ}_VerifyBamID2.stderr > !{id}_!{params.panel_id}_adjustMQ!{params.adjustMQ}_VerifyBamID2.stdout
   '''
}

process haplocheck {
   tag "${id}"

   cpus params.haplocheck_cpus
   memory { params.haplocheck_mem.plus(task.attempt.minus(1).multiply(1))+' GB' }
   time { task.attempt == 3 ? '12h' : params.haplocheck_timeout }
   errorStrategy { task.exitStatus in ([1]+(134..140).collect()) ? 'retry' : 'terminate' }
   maxRetries 2

   publishDir path: "${params.output_dir}/logs", mode: 'copy', pattern: '*.std{err,out}'
   publishDir path: "${params.output_dir}/haplocheck_outputs", mode: 'copy', pattern: '*_report.html'
   publishDir path: "${params.output_dir}/haplocheck_outputs", mode: 'copy', pattern: '*.txt'

   input:
   tuple val(id), file(bambai) from bams_haplocheck
   file rcrs

   output:
   tuple path("${id}_mutserve.stderr"), path("${id}_mutserve.stdout"), path("${id}_haplocheck.stderr"), path("${id}_haplocheck.stdout") into haplocheck_logs
   tuple path("${id}_haplocheck_report.html"), path("${id}_haplocheck_contamination.txt"), path("${id}_haplocheck_contamination.raw.txt") into haplocheck_outputs

   shell:
   '''
   module load !{params.mod_mutserve}
   module load !{params.mod_haplocheck}
   mutserve call --reference !{rcrs} --threads !{task.cpus} --output !{id}_mutserve.vcf.gz !{bambai[0]} 2> !{id}_mutserve.stderr > !{id}_mutserve.stdout
   haplocheck --threads !{task.cpus} --out !{id} !{id}_mutserve.vcf.gz 2> !{id}_haplocheck.stderr > !{id}_haplocheck.stdout
   cp !{id}/report.html !{id}_haplocheck_report.html
   cp !{id}/contamination.txt !{id}_haplocheck_contamination.txt
   cp !{id}/contamination.raw.txt !{id}_haplocheck_contamination.raw.txt
   '''
}

process somalier_extract {
   tag "${id}"

   cpus params.extract_cpus
   memory { params.extract_mem.plus(task.attempt.minus(1).multiply(1))+' GB' }
   time { task.attempt == 2 ? '12h' : params.extract_timeout }
   errorStrategy { task.exitStatus in ([1]+(134..140).collect()) ? 'retry' : 'terminate' }
   maxRetries 1

   publishDir path: "${params.output_dir}/logs", mode: 'copy', pattern: '*.std{err,out}'

   input:
   tuple val(id), file(bambai) from bams_somalier
   file ref
   file somalier_sites

   output:
   tuple path("somalier_extract_${id}.stderr"), path("somalier_extract_${id}.stdout") into somalier_extract_logs
   path("${id}.somalier") into somalier_extracted

   shell:
   '''
   module load !{params.mod_somalier}
   somalier extract -d ./ --sample-prefix !{id} --sites !{somalier_sites} -f !{ref} !{bambai[0]} 2> somalier_extract_!{id}.stderr > somalier_extract_!{id}.stdout
   '''
}

process somalier_relate {
//   tag ""

   cpus params.relate_cpus
   memory { params.relate_mem.plus(task.attempt.minus(1).multiply(1))+' GB' }
   time { task.attempt == 2 ? '12h' : params.relate_timeout }
   errorStrategy { task.exitStatus in ([1]+(134..140).collect()) ? 'retry' : 'terminate' }
   maxRetries 1

   publishDir path: "${params.output_dir}/logs", mode: 'copy', pattern: '*.std{err,out}'
   publishDir path: "${params.output_dir}/somalier", mode: 'copy', pattern: '*.{html,tsv,txt}'

   input:
   path("*") from somalier_extracted.collect()

   output:
   tuple path("somalier_relate.stderr"), path("somalier_relate.stdout") into somalier_relate_logs
   tuple path("${params.run_name}_somalier.groups.tsv"), path("${params.run_name}_somalier.pairs.tsv"), path("${params.run_name}_somalier.samples.tsv"), path("${params.run_name}_somalier.html"), path("${params.run_name}_somalier_inferred_relationships.txt") into somalier_relate_output

   shell:
   '''
   module load !{params.mod_somalier}
   SOMALIER_REPORT_ALL_PAIRS=1 somalier relate --infer -o !{params.run_name}_somalier "./*.somalier" 2> somalier_relate.stderr > somalier_relate.stdout
   !{projectDir}/HumanPopGenScripts/Relatedness/extract_families_somalier.awk !{params.run_name}_somalier.samples.tsv !{params.run_name}_somalier.pairs.tsv > !{params.run_name}_somalier_inferred_relationships.txt
   '''
}
